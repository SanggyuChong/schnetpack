{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import schnetpack as spk\n",
    "from schnetpack.datasets import QM9\n",
    "import schnetpack.transform as trn\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "qm9tut = './examples/tutorials/qm9tut'\n",
    "if not os.path.exists(qm9tut):\n",
    "    os.makedirs(qm9tut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: split.npz: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "%rm split.npz\n",
    "\n",
    "qm9data = QM9(\n",
    "    './examples/tutorials/qm9.db', \n",
    "    batch_size=100,\n",
    "    num_train=1000,\n",
    "    num_val=1000,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=5.),\n",
    "        trn.RemoveOffsets(QM9.U0, remove_mean=True, remove_atomrefs=True),\n",
    "        trn.CastTo32()\n",
    "    ],\n",
    "    property_units={QM9.U0: 'eV'},\n",
    "    num_workers=1,\n",
    "    split_file=os.path.join(qm9tut, \"split.npz\"),\n",
    "    pin_memory=True, # set to false, when not using a GPU\n",
    "    load_properties=[QM9.U0], #only load U0 property\n",
    ")\n",
    "qm9data.prepare_data()\n",
    "qm9data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U0 of hyrogen: -13.613121032714844 eV\n",
      "U0 of carbon: -1029.863037109375 eV\n",
      "U0 of oxygen: -2042.611083984375 eV\n"
     ]
    }
   ],
   "source": [
    "atomrefs = qm9data.train_dataset.atomrefs\n",
    "print('U0 of hyrogen:', atomrefs[QM9.U0][1].item(), 'eV')\n",
    "print('U0 of carbon:', atomrefs[QM9.U0][6].item(), 'eV')\n",
    "print('U0 of oxygen:', atomrefs[QM9.U0][8].item(), 'eV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean atomization energy / atom: -4.246610436332558\n",
      "Std. dev. atomization energy / atom: 0.18493500286437978\n"
     ]
    }
   ],
   "source": [
    "means, stddevs = qm9data.get_stats(\n",
    "    QM9.U0, divide_by_atoms=True, remove_atomref=True\n",
    ")\n",
    "print('Mean atomization energy / atom:', means.item())\n",
    "print('Std. dev. atomization energy / atom:', stddevs.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cutoff = 5.\n",
    "n_atom_basis = 30\n",
    "\n",
    "pairwise_distance = spk.atomistic.PairwiseDistances() # calculates pairwise distances between atoms\n",
    "radial_basis = spk.nn.GaussianRBF(n_rbf=20, cutoff=cutoff)\n",
    "schnet = spk.representation.PaiNN(\n",
    "    n_atom_basis=n_atom_basis, n_interactions=3,\n",
    "    radial_basis=radial_basis,\n",
    "    cutoff_fn=spk.nn.CosineCutoff(cutoff)\n",
    ")\n",
    "pred_U0 = spk.atomistic.Atomwise(n_in=n_atom_basis, output_key=QM9.U0)\n",
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=schnet,\n",
    "    input_modules=[pairwise_distance],\n",
    "    output_modules=[pred_U0],\n",
    "    postprocessors=[trn.CastTo64(), trn.AddOffsets(QM9.U0, add_mean=True, add_atomrefs=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_U0 = spk.task.ModelOutput(\n",
    "    name=QM9.U0,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=1.,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    outputs=[output_U0],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | model   | NeuralNetworkPotential | 39.6 K\n",
      "1 | outputs | ModuleList             | 0     \n",
      "---------------------------------------------------\n",
      "39.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "39.6 K    Total params\n",
      "0.158     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 100. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10/10 [00:11<00:00,  0.85it/s, v_num=4, val_loss=7.860]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10/10 [00:11<00:00,  0.85it/s, v_num=4, val_loss=7.860]\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir=qm9tut)\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(qm9tut, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=qm9tut,\n",
    "    max_epochs=3, # for testing, we restrict the number of epochs\n",
    "    accelerator=\"cpu\",\n",
    ")\n",
    "trainer.fit(task, datamodule=qm9data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ase import Atoms\n",
    "\n",
    "best_model = torch.load(os.path.join(qm9tut, 'best_inference_model'), map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llpr_model = spk.model.LLPredRigidityNNP(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = {'E': 1, 'F': 1, 'S': 1}\n",
    "llpr_model.compute_covariance(qm9data.train_dataloader(), weights=weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llpr_model.compute_inv_covariance(1e-5, 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters found beyond the designated parameter space!\n",
      "Calibrated LLPR parameters:\tC = 9.2547E+09\tsigma = 6.4591E-07\n"
     ]
    }
   ],
   "source": [
    "from schnetpack.utils.llpr import calibrate_llpr_params\n",
    "\n",
    "calibrate_llpr_params(llpr_model, qm9data.train_dataloader(), energy_key=QM9.U0, function=\"ssl\", n_samples_per_bin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result dictionary: {'energy_U0': tensor([-12419.0985, -12786.2532,  -9498.9090, -11004.8840, -10935.9251,\n",
      "        -11511.2783, -11441.8662,  -9923.3172, -11546.4803, -12786.8764,\n",
      "        -11512.3940, -12141.5461, -11511.3243, -11982.7758, -10499.3846,\n",
      "        -10568.9323, -11407.3844, -10900.9702, -10569.2442, -11372.0992,\n",
      "        -11739.6564, -10796.5143, -10970.3892, -12926.1035, -10878.8831,\n",
      "         -9923.7213, -10569.4217, -12996.2791,  -9452.2065, -11948.4279,\n",
      "        -11336.8837,  -9831.4842, -11913.3679, -11983.8387, -12489.5510,\n",
      "        -11546.8487, -12453.9706, -12315.3002, -10832.0862, -10533.8148,\n",
      "        -10935.4397, -10569.0611, -11878.0266, -10464.7134,  -9935.9791,\n",
      "        -10604.4055, -11949.2451, -11476.6294, -11947.7303, -12524.5107,\n",
      "        -11982.7051, -10796.4044, -11948.0333,  -9360.0222,  -9922.5793,\n",
      "        -11372.3400, -11511.6595, -11948.6420, -11005.9243, -11809.7613,\n",
      "        -11948.1098, -12210.5134, -11983.3145, -11337.7648, -12524.5614,\n",
      "        -10533.4431, -10865.1945, -10830.2717, -10971.0805, -10534.6796,\n",
      "        -11337.2154, -11546.5436, -11983.5324, -10393.9766, -11372.3433,\n",
      "        -11489.9448,  -9499.9503, -10499.3021, -11441.8772, -13466.4347,\n",
      "        -11407.1325, -10360.0336, -10302.9804,  -9533.8796, -10935.9824,\n",
      "         -9569.7740, -11546.4558,  -9901.2662, -11947.8080, -11809.1102,\n",
      "         -9901.3266, -10970.5810, -12489.1558, -10499.5047, -12454.4037,\n",
      "        -11511.4855, -11475.9140, -10464.3442, -11233.4714, -10878.9002],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>), 'll_feats': tensor([[ 9.7489, -0.3643, 12.0035,  ...,  0.1996,  8.7255,  1.1282],\n",
      "        [12.3540,  2.0878, 15.0806,  ..., -0.5598,  7.1285,  1.3960],\n",
      "        [22.1551, -2.8506, 27.0011,  ...,  3.0974,  4.3221,  6.5847],\n",
      "        ...,\n",
      "        [14.8128, -2.2146, 18.0469,  ...,  2.2310,  6.9522,  3.5613],\n",
      "        [17.1795,  1.8672, 15.8923,  ...,  0.4077,  4.2686,  5.3090],\n",
      "        [16.3073, -0.4980, 18.3016,  ...,  1.5213,  5.6970,  4.1387]],\n",
      "       dtype=torch.float64, grad_fn=<ToCopyBackward0>), 'uncertainty': tensor([[1.2553e+08],\n",
      "        [1.7439e+08],\n",
      "        [1.8059e+08],\n",
      "        [1.1701e+08],\n",
      "        [1.9508e+08],\n",
      "        [1.2919e+08],\n",
      "        [2.1783e+08],\n",
      "        [1.4143e+08],\n",
      "        [5.7363e+07],\n",
      "        [1.5068e+08],\n",
      "        [1.9629e+08],\n",
      "        [4.1646e+08],\n",
      "        [1.2270e+08],\n",
      "        [1.3061e+08],\n",
      "        [1.2741e+08],\n",
      "        [3.8221e+08],\n",
      "        [1.5016e+08],\n",
      "        [9.1430e+07],\n",
      "        [7.1122e+07],\n",
      "        [9.8762e+07],\n",
      "        [3.4025e+08],\n",
      "        [1.9256e+08],\n",
      "        [1.3029e+08],\n",
      "        [1.0793e+08],\n",
      "        [5.6960e+07],\n",
      "        [1.3832e+08],\n",
      "        [1.6108e+08],\n",
      "        [3.8255e+08],\n",
      "        [3.3385e+08],\n",
      "        [8.7421e+07],\n",
      "        [1.2878e+08],\n",
      "        [1.8359e+08],\n",
      "        [1.1333e+08],\n",
      "        [2.2675e+08],\n",
      "        [1.2828e+08],\n",
      "        [1.0484e+08],\n",
      "        [1.2180e+08],\n",
      "        [1.3549e+08],\n",
      "        [2.2647e+08],\n",
      "        [1.2592e+08],\n",
      "        [7.8912e+07],\n",
      "        [8.5337e+07],\n",
      "        [1.8599e+08],\n",
      "        [1.8871e+08],\n",
      "        [9.7174e+07],\n",
      "        [1.6004e+08],\n",
      "        [2.1073e+08],\n",
      "        [1.5237e+08],\n",
      "        [1.2118e+08],\n",
      "        [1.2187e+08],\n",
      "        [1.6100e+08],\n",
      "        [1.7017e+08],\n",
      "        [8.4972e+07],\n",
      "        [1.1573e+08],\n",
      "        [1.0013e+08],\n",
      "        [7.4328e+07],\n",
      "        [8.6632e+07],\n",
      "        [8.2282e+07],\n",
      "        [1.3620e+08],\n",
      "        [2.4486e+08],\n",
      "        [5.6532e+07],\n",
      "        [1.5561e+08],\n",
      "        [1.4198e+08],\n",
      "        [9.1969e+07],\n",
      "        [1.2585e+08],\n",
      "        [1.9865e+08],\n",
      "        [2.0947e+08],\n",
      "        [2.3090e+08],\n",
      "        [1.2602e+08],\n",
      "        [1.0870e+08],\n",
      "        [1.7800e+08],\n",
      "        [8.7750e+07],\n",
      "        [8.3540e+07],\n",
      "        [2.4231e+08],\n",
      "        [6.2160e+07],\n",
      "        [1.1498e+08],\n",
      "        [1.0894e+08],\n",
      "        [2.3193e+08],\n",
      "        [1.8054e+08],\n",
      "        [1.8300e+08],\n",
      "        [1.1346e+08],\n",
      "        [9.1330e+07],\n",
      "        [1.2590e+08],\n",
      "        [1.4165e+08],\n",
      "        [9.2593e+07],\n",
      "        [2.0173e+08],\n",
      "        [6.8619e+07],\n",
      "        [5.9267e+07],\n",
      "        [7.9283e+07],\n",
      "        [1.2591e+08],\n",
      "        [7.0167e+07],\n",
      "        [2.3210e+08],\n",
      "        [8.0288e+07],\n",
      "        [1.5748e+08],\n",
      "        [1.8000e+08],\n",
      "        [1.3396e+08],\n",
      "        [1.1440e+08],\n",
      "        [1.8619e+08],\n",
      "        [2.1279e+08],\n",
      "        [1.2364e+08]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "for batch in qm9data.test_dataloader():\n",
    "    result = llpr_model(batch)\n",
    "    print(\"Result dictionary:\", result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['energy_U0', 'll_feats', 'uncertainty'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import schnetpack as spk\n",
    "import schnetpack.transform as trn\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "forcetut = './forcetut'\n",
    "if not os.path.exists(forcetut):\n",
    "    os.makedirs(forcetut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 12.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from schnetpack.datasets import MD17\n",
    "\n",
    "ethanol_data = MD17(\n",
    "    os.path.join(forcetut,'ethanol.db'),\n",
    "    molecule='ethanol',\n",
    "    batch_size=10,\n",
    "    num_train=1000,\n",
    "    num_val=1000,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=5.),\n",
    "        trn.RemoveOffsets(MD17.energy, remove_mean=True, remove_atomrefs=False),\n",
    "        trn.CastTo32()\n",
    "    ],\n",
    "    num_workers=1,\n",
    "    pin_memory=True, # set to false, when not using a GPU\n",
    ")\n",
    "ethanol_data.prepare_data()\n",
    "ethanol_data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5.\n",
    "n_atom_basis = 30\n",
    "\n",
    "pairwise_distance = spk.atomistic.PairwiseDistances() # calculates pairwise distances between atoms\n",
    "radial_basis = spk.nn.GaussianRBF(n_rbf=20, cutoff=cutoff)\n",
    "schnet = spk.representation.SchNet(\n",
    "    n_atom_basis=n_atom_basis, n_interactions=3,\n",
    "    radial_basis=radial_basis,\n",
    "    cutoff_fn=spk.nn.CosineCutoff(cutoff)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_energy = spk.atomistic.Atomwise(n_in=n_atom_basis, output_key=MD17.energy)\n",
    "pred_forces = spk.atomistic.Forces(energy_key=MD17.energy, force_key=MD17.forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=schnet,\n",
    "    input_modules=[pairwise_distance],\n",
    "    output_modules=[pred_energy, pred_forces],\n",
    "    postprocessors=[\n",
    "        trn.CastTo64(),\n",
    "        trn.AddOffsets(MD17.energy, add_mean=True, add_atomrefs=False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_energy = spk.task.ModelOutput(\n",
    "    name=MD17.energy,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=0.01,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")\n",
    "\n",
    "output_forces = spk.task.ModelOutput(\n",
    "    name=MD17.forces,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=0.99,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    outputs=[output_energy, output_forces],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | model   | NeuralNetworkPotential | 16.4 K\n",
      "1 | outputs | ModuleList             | 0     \n",
      "---------------------------------------------------\n",
      "16.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.4 K    Total params\n",
      "0.066     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 10. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 100/100 [00:10<00:00,  9.39it/s, v_num=2, val_loss=280.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 100/100 [00:10<00:00,  9.36it/s, v_num=2, val_loss=280.0]\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir=forcetut)\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(forcetut, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=forcetut,\n",
    "    max_epochs=3, # for testing, we restrict the number of epochs\n",
    "    accelerator=\"cpu\",\n",
    ")\n",
    "trainer.fit(task, datamodule=ethanol_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ase import Atoms\n",
    "\n",
    "best_model = torch.load(os.path.join(forcetut, 'best_inference_model'), map_location='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result dictionary: {'energy': tensor([-97210.0654, -97210.7605, -97206.9073, -97209.9240, -97199.7050,\n",
      "        -97211.4904, -97204.5015, -97205.6022, -97211.4079, -97206.9409],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>), 'forces': tensor([[ 10.6494,  21.3353, -17.2408],\n",
      "        [ 15.9638,   4.8310, -14.0813],\n",
      "        [-27.4557,   3.7567,   9.0707],\n",
      "        [ -6.3261, -13.8017,   5.1199],\n",
      "        [ -4.5373,  -6.0107,  22.2705],\n",
      "        [  3.2681, -15.2702,   1.6571],\n",
      "        [ -9.1851,   2.5905,   2.1877],\n",
      "        [  3.9397,   4.6313,   6.4225],\n",
      "        [ 13.6832,  -2.0622, -15.4063],\n",
      "        [-11.1396,  -9.6098,  12.4538],\n",
      "        [-20.4713, -26.6090,  -6.5079],\n",
      "        [ -2.0376,  -6.9788,  -4.8157],\n",
      "        [ 32.8856,  10.1171, -28.7315],\n",
      "        [-12.6309,   7.8671,  16.8562],\n",
      "        [ 13.2541,  -1.9664, -10.1295],\n",
      "        [  5.5059,  -2.5391,   1.1043],\n",
      "        [-14.7514,  30.9938,  11.0199],\n",
      "        [  9.3852,  -1.2750,   8.7502],\n",
      "        [ -1.0158, -11.8537, -13.1450],\n",
      "        [-50.1665,  25.5136,   4.4517],\n",
      "        [ -8.8511,  16.8814,  10.2569],\n",
      "        [  4.3817,   5.4594,  -5.6186],\n",
      "        [ -0.3949,   7.0462,  11.7310],\n",
      "        [ -8.3237, -19.4528,  -5.8889],\n",
      "        [ 36.4753, -10.9853, -16.0308],\n",
      "        [ 24.2255,  -5.1498,  27.5586],\n",
      "        [  3.6695,  -7.4590, -13.3149],\n",
      "        [-11.1598, -26.1561, -28.9548],\n",
      "        [-16.3707,  -7.9499,   5.9345],\n",
      "        [ -8.8287,   8.0437,  -4.2356],\n",
      "        [  1.0799,   0.7201,  21.3921],\n",
      "        [ -7.2555,  52.7986,  -1.1743],\n",
      "        [  1.8761,   5.2075,  -1.2524],\n",
      "        [  3.6940,   2.7723,  -4.6030],\n",
      "        [ 12.0403,  -3.2966,  -2.3319],\n",
      "        [ 24.9244, -32.1395,  15.2254],\n",
      "        [-45.8945,  41.5406, -12.8510],\n",
      "        [  8.4484, -10.9269, -13.4095],\n",
      "        [ -1.0762,  32.4088, -24.4306],\n",
      "        [ 19.2889,  -3.9129,  24.5209],\n",
      "        [ 26.9184, -33.9529, -32.7304],\n",
      "        [-11.1344,   5.8351,   0.9070],\n",
      "        [  0.1359,   4.4435,   7.5051],\n",
      "        [ -1.7059,   2.0996,   8.6385],\n",
      "        [  5.0194, -37.5349,  41.8499],\n",
      "        [  3.1868,  -2.4431,  20.0559],\n",
      "        [  0.4517,  -4.5997,  -4.6574],\n",
      "        [-22.9159,  11.0995,   3.0240],\n",
      "        [  2.9702,  -0.3192,  -1.4776],\n",
      "        [-15.4154,  -5.1569, -17.0282],\n",
      "        [ -4.6637,   0.6547,  -4.9493],\n",
      "        [  7.6749,  -6.3606,   9.6741],\n",
      "        [  6.9180,   5.4292, -11.7466],\n",
      "        [ 21.7932,   1.6961,   7.1050],\n",
      "        [ 30.3165,  -5.1335,  30.2453],\n",
      "        [-24.2783,  -5.7060,  13.3333],\n",
      "        [-19.3706,   6.5424,   7.2299],\n",
      "        [-25.4915,  -4.5673, -13.8750],\n",
      "        [ 13.1558,   5.3191,  -2.4585],\n",
      "        [ 43.4572,  -0.9305, -14.1559],\n",
      "        [-13.8761,  -3.4775, -16.2225],\n",
      "        [ -4.2154,  15.0739,   5.5240],\n",
      "        [  0.3024,  -7.1206,  -9.6206],\n",
      "        [-27.7084, -12.7542,  26.3247],\n",
      "        [-15.3000,  18.8580,  45.5614],\n",
      "        [-10.6283,  16.4833, -16.1737],\n",
      "        [ 46.8600,  18.5184, -25.8664],\n",
      "        [  2.8538,  -0.6177,   7.2491],\n",
      "        [  0.9151,  -9.6656,  -1.7237],\n",
      "        [ 12.5840,  -7.6695, -40.3120],\n",
      "        [ -3.9172, -11.2748,  -4.8915],\n",
      "        [ -5.6591, -11.8778,   9.8320],\n",
      "        [ -4.0668,   9.3539,  30.0829],\n",
      "        [ -5.0306, -26.3864, -25.7381],\n",
      "        [  0.2278,  29.2231,   6.1005],\n",
      "        [ -7.1882,  -1.1997,  -9.1451],\n",
      "        [  1.7977,   3.0438,   0.9556],\n",
      "        [ 14.4694,   4.3800,   3.3136],\n",
      "        [ -0.2895,  10.2531,   8.9825],\n",
      "        [ -2.0913,  -2.2665,   7.4177],\n",
      "        [  2.1714, -26.4013, -21.9695],\n",
      "        [  1.4098,  38.1291, -29.0452],\n",
      "        [ 12.6468, -10.1174,  29.9332],\n",
      "        [  0.6309,  -1.2959, -19.2811],\n",
      "        [  3.4671, -22.3424,   1.3375],\n",
      "        [  5.1118, -13.0774,  36.6285],\n",
      "        [  0.4320,  22.6741, -10.2157],\n",
      "        [-26.7276, -11.7566, -24.7589],\n",
      "        [  0.1983,  -1.5349,  10.5161],\n",
      "        [  2.8309,  -0.6786,   4.8856]], dtype=torch.float64,\n",
      "       grad_fn=<ToCopyBackward0>), 'll_feats': tensor([[ 2.7911e+01,  4.7771e+00,  1.5750e+01,  6.8691e+01, -1.3249e+00,\n",
      "          4.0001e+01,  8.8785e+00,  7.5007e-01,  4.0417e+01,  5.4743e+01,\n",
      "         -1.0211e+00,  2.8827e+01,  1.3300e+01,  2.0625e+01, -2.0437e+00],\n",
      "        [ 2.9171e+01,  3.8698e+00,  1.6528e+01,  7.4904e+01, -1.1516e+00,\n",
      "          4.1655e+01,  9.5936e+00,  1.1783e+00,  4.3722e+01,  5.7671e+01,\n",
      "         -8.9258e-01,  3.0135e+01,  1.4837e+01,  2.2488e+01, -1.8387e+00],\n",
      "        [ 2.8191e+01,  5.2711e+00,  1.5367e+01,  6.8909e+01, -1.0538e+00,\n",
      "          3.9502e+01,  9.4167e+00,  6.7550e-01,  3.9058e+01,  5.3402e+01,\n",
      "         -1.0685e+00,  2.9602e+01,  1.5111e+01,  2.2425e+01, -2.0039e+00],\n",
      "        [ 2.9752e+01,  4.9508e+00,  1.4387e+01,  7.3870e+01, -1.7254e+00,\n",
      "          4.0981e+01,  8.9262e+00,  6.4166e-01,  4.3274e+01,  5.7329e+01,\n",
      "         -9.6780e-01,  2.8305e+01,  1.3669e+01,  2.1668e+01, -2.0345e+00],\n",
      "        [ 2.9781e+01,  4.9485e+00,  1.2382e+01,  7.1369e+01, -1.3054e+00,\n",
      "          4.1911e+01,  8.8287e+00, -7.3905e-01,  3.9789e+01,  5.2042e+01,\n",
      "         -1.0454e+00,  2.9695e+01,  2.0077e+01,  2.9474e+01, -1.7607e+00],\n",
      "        [ 2.8349e+01,  4.4207e+00,  1.6512e+01,  6.9439e+01, -1.4058e+00,\n",
      "          3.9730e+01,  1.0195e+01,  3.2856e-01,  4.1206e+01,  5.4597e+01,\n",
      "         -1.0617e+00,  2.6962e+01,  1.4300e+01,  2.0871e+01, -1.8303e+00],\n",
      "        [ 2.8150e+01,  4.4095e+00,  1.7448e+01,  6.9919e+01,  2.0621e+00,\n",
      "          4.0725e+01,  9.0023e+00,  3.6222e+00,  4.0064e+01,  5.3788e+01,\n",
      "         -9.9356e-01,  2.7829e+01,  1.8615e+01,  2.5508e+01, -1.8545e+00],\n",
      "        [ 2.8030e+01,  4.1891e+00,  1.3762e+01,  6.9588e+01, -1.2732e+00,\n",
      "          4.1203e+01,  8.7467e+00,  6.5052e-02,  4.0632e+01,  5.2857e+01,\n",
      "         -9.5806e-01,  2.7647e+01,  1.6862e+01,  2.4985e+01, -1.9627e+00],\n",
      "        [ 2.8349e+01,  5.3729e+00,  1.6085e+01,  6.9975e+01, -1.6094e+00,\n",
      "          4.0086e+01,  9.0810e+00, -3.2307e-01,  4.1408e+01,  5.4815e+01,\n",
      "         -1.0168e+00,  2.7063e+01,  1.3181e+01,  2.0613e+01, -1.9750e+00],\n",
      "        [ 2.9154e+01,  5.0828e+00,  1.5887e+01,  7.1511e+01, -9.2815e-01,\n",
      "          3.9819e+01,  8.4050e+00,  8.6007e-01,  3.9086e+01,  5.4610e+01,\n",
      "         -9.3011e-01,  2.9887e+01,  1.4440e+01,  2.2823e+01, -1.8711e+00]],\n",
      "       dtype=torch.float64, grad_fn=<ToCopyBackward0>), 'll_feats_grad_F': tensor([[[ 8.2359e-01, -5.8327e+00,  6.0668e+00,  ...,  2.2333e+01,\n",
      "           2.1967e+01,  6.9800e-01],\n",
      "         [ 4.1591e+00,  6.6849e-01, -1.1806e+01,  ...,  1.1797e+01,\n",
      "           1.4547e+01,  2.6642e-01],\n",
      "         [ 1.1142e+00, -2.0581e+00, -1.8063e+00,  ..., -1.1279e+00,\n",
      "          -2.2977e+00,  3.2775e-01]],\n",
      "\n",
      "        [[-5.4469e-01,  4.7620e+00,  1.7679e+00,  ..., -4.5817e+00,\n",
      "          -5.6354e+00, -9.3711e-01],\n",
      "         [-3.2197e-01,  1.3855e+00,  1.2958e+00,  ..., -2.4283e+00,\n",
      "          -2.2423e+00, -1.7181e-01],\n",
      "         [-3.1435e+00,  1.2287e+00,  8.6517e+00,  ..., -1.0392e+01,\n",
      "          -1.5349e+01, -3.7202e-01]],\n",
      "\n",
      "        [[ 6.1598e-02, -3.1634e+00,  6.8387e-01,  ..., -9.7015e+00,\n",
      "          -1.6051e+01,  2.4807e-01],\n",
      "         [ 1.3445e-01, -5.3971e-01,  4.1229e+00,  ...,  2.0860e+00,\n",
      "           3.7822e+00,  1.0986e-01],\n",
      "         [-1.2380e+00, -9.1232e-01,  1.6163e+00,  ...,  4.9899e+00,\n",
      "           8.3980e+00,  4.6362e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.0632e+00,  9.8442e-01,  9.3681e+00,  ..., -1.1733e+01,\n",
      "          -1.6505e+01, -2.4534e-01],\n",
      "         [-2.6332e+00, -3.2418e+00,  3.7909e+00,  ...,  6.6831e-01,\n",
      "          -1.3480e+00,  2.9019e-01],\n",
      "         [-4.9250e+00, -2.9492e+00,  8.3048e+00,  ..., -6.2557e+00,\n",
      "          -1.0071e+01,  2.4689e-01]],\n",
      "\n",
      "        [[-1.3479e-02,  3.1822e+00, -2.1147e+00,  ..., -6.2679e+00,\n",
      "          -6.4290e+00, -2.3354e-01],\n",
      "         [-6.9364e-01, -1.7036e+00, -5.5341e-01,  ...,  7.1345e-01,\n",
      "           4.8331e-01,  1.6756e-01],\n",
      "         [ 2.9209e+00,  1.8703e+00, -1.7919e+00,  ...,  3.3591e+00,\n",
      "           4.6034e+00, -1.6415e-01]],\n",
      "\n",
      "        [[ 2.9476e+00,  2.9090e-01, -5.1111e+00,  ..., -1.5166e-01,\n",
      "           5.1146e+00, -3.7515e-01],\n",
      "         [ 6.6985e-01,  4.8299e-01, -2.6008e+00,  ..., -9.7219e-01,\n",
      "           2.9598e+00,  5.6933e-02],\n",
      "         [ 4.5210e+00,  7.3865e-01, -4.1723e+00,  ...,  1.9952e+00,\n",
      "           4.6559e+00, -1.5452e-01]]], dtype=torch.float64,\n",
      "       grad_fn=<ToCopyBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "llpr_model = spk.model.LLPredRigidityNNP(best_model, consider_ll_feat_gradients=True)#, save_ll_feat_per_atom=True)\n",
    "weight_dict = {'E': 1, 'F': 1, 'S': 1}\n",
    "# llpr_model.compute_covariance(ethanol_data.train_dataloader(), weights=weight_dict)\n",
    "# llpr_model.compute_inv_covariance(1e-5, 1e-8)\n",
    "\n",
    "for batch in ethanol_data.val_dataloader():\n",
    "    result = llpr_model(batch)\n",
    "    print(\"Result dictionary:\", result)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = {'E': 1, 'F': 1, 'S': 1}\n",
    "llpr_model.compute_covariance(ethanol_data.train_dataloader(), weights=weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "llpr_model.compute_inv_covariance(1e-5, 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result dictionary: {'energy': tensor([-97204.9312, -97209.5246, -97212.8567, -97206.8458, -97208.1758,\n",
      "        -97200.7451, -97209.8244, -97206.6482, -97208.6151, -97206.2706],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>), 'forces': tensor([[-19.3452, -24.4908, -33.1036],\n",
      "        [-15.3924,  34.1064,  -6.9776],\n",
      "        [-21.6759,  10.8351,  13.2340],\n",
      "        [  8.7621,   4.4343,  18.5151],\n",
      "        [  4.6606,  20.3840,   7.1246],\n",
      "        [ 14.8669,  -2.1212,  -2.3163],\n",
      "        [ 11.6235, -40.5081,   5.8096],\n",
      "        [ 10.9932,  -6.5715,  -0.9546],\n",
      "        [  5.5072,   3.9317,  -1.3313],\n",
      "        [-10.5130,   5.1577,  14.9365],\n",
      "        [ -0.1585, -20.9157,  21.9732],\n",
      "        [ 13.1919,  28.6071,  -2.9437],\n",
      "        [ -3.0789,  -2.2282,  -3.6631],\n",
      "        [  5.3025,   1.0228,  -5.1780],\n",
      "        [ 17.7746,  -6.9433,  -6.3051],\n",
      "        [ -9.7262,  28.2738, -14.9301],\n",
      "        [ -1.5465,  -4.9229,  -4.3121],\n",
      "        [-11.2459, -28.0512,   0.4224],\n",
      "        [ 13.4215,   6.5385,  -3.6206],\n",
      "        [-18.4862, -14.8544,  15.1218],\n",
      "        [-17.4845,  -5.5990,  -7.1099],\n",
      "        [  6.8387,  -9.8009,   9.7098],\n",
      "        [ -5.1681,  -0.2512,  -5.8796],\n",
      "        [ -1.1295,   3.3447,  -1.1670],\n",
      "        [  1.2716,   1.9158,  -3.6748],\n",
      "        [  7.8501,  14.2822, -12.3814],\n",
      "        [ 12.8865,   4.4241,   9.0018],\n",
      "        [ 14.1275,  -5.6995,  -4.6380],\n",
      "        [ -8.6721,  12.2515,  45.2337],\n",
      "        [-23.4318,   6.4491,  -3.3663],\n",
      "        [ -1.8044,  17.6502,  -4.6271],\n",
      "        [ -7.9547,  -4.3068,  14.8197],\n",
      "        [  7.3085,  10.9212,  -3.7630],\n",
      "        [  6.0940, -33.3375, -23.9510],\n",
      "        [ 12.2348,  -0.3441, -13.3125],\n",
      "        [  2.0983,  -3.5841,  -6.3955],\n",
      "        [ 22.2457,  18.9087,   8.2108],\n",
      "        [  9.0846, -37.8468,  17.4815],\n",
      "        [-16.8822,   5.6335,  -2.6791],\n",
      "        [ -6.2425, -32.9404,  -7.4280],\n",
      "        [  3.9982,   2.3182,  12.4472],\n",
      "        [-20.9195,  13.0637,   1.8459],\n",
      "        [ -4.5271,  15.5492, -24.2496],\n",
      "        [  9.1951,  16.7438,  -5.7111],\n",
      "        [  4.0478,  -1.4299,   0.0823],\n",
      "        [ 26.6659,  15.7663,  14.7428],\n",
      "        [ 15.1564, -40.2057, -14.5603],\n",
      "        [ 13.4481,  21.7477, -11.4963],\n",
      "        [ 11.7447,  -4.2714, -14.1989],\n",
      "        [-17.4513,   4.7649,  -7.7582],\n",
      "        [ 12.3998,  32.3576,  26.2832],\n",
      "        [  5.3188,  -4.8390,   1.7371],\n",
      "        [-45.1210,  -0.7897,  -4.2387],\n",
      "        [-22.1613, -24.5308,   9.4891],\n",
      "        [  0.4361,  -9.2885,   6.1930],\n",
      "        [  7.5728,  -1.6344,  47.2679],\n",
      "        [-25.1720,  -5.9651,   1.3904],\n",
      "        [ -3.4365,   8.6324,   3.6869],\n",
      "        [ 18.1768,  -0.5471, -30.2490],\n",
      "        [  0.8830,  13.1591,  -5.7973],\n",
      "        [ -3.8892,  -7.0984, -15.3443],\n",
      "        [ -3.0665,  -0.1225,  -8.0576],\n",
      "        [  8.4955,   2.8646,   0.9098],\n",
      "        [  5.7199,  52.0513, -28.8369],\n",
      "        [ -9.7026,  15.7048,  19.2914],\n",
      "        [  1.2211,  -3.9162,   9.3115],\n",
      "        [  0.9096,  -3.4056,   7.2685],\n",
      "        [ -5.1962, -45.3192,  18.3275],\n",
      "        [ -6.8567,   6.4000, -24.5596],\n",
      "        [ -0.8280,  -5.3464,  11.7869],\n",
      "        [  0.7244,  -8.4485,  -6.3908],\n",
      "        [ 14.0086,  -7.7201,  -6.1985],\n",
      "        [ 15.6088,  10.5672, -15.6974],\n",
      "        [ 29.6132,  17.8209, -17.1366],\n",
      "        [-17.1339,   5.5224,  -1.4562],\n",
      "        [  4.7985,  -1.7902,   3.8433],\n",
      "        [  4.3117,   8.9153,  31.1301],\n",
      "        [-17.7435, -46.7608,  25.5663],\n",
      "        [-23.8128,  18.7103,   2.3437],\n",
      "        [ -2.8870,  -4.7047, -21.2678],\n",
      "        [  7.2449,  -8.2802,  -7.3254],\n",
      "        [ 33.2467,  -9.0607, -15.1145],\n",
      "        [ 23.5132,  -6.1895,  40.1601],\n",
      "        [ -8.6729,   4.5662,  -9.7776],\n",
      "        [-23.8637,  -0.9642,  12.6256],\n",
      "        [  8.1180,   5.0861,  21.6753],\n",
      "        [-20.9444, -12.9388,  -6.0901],\n",
      "        [ -9.6628,  34.0309, -28.0746],\n",
      "        [ -7.0323, -20.0579, -19.1366],\n",
      "        [  5.2983,   5.5278,   3.7324]], dtype=torch.float64,\n",
      "       grad_fn=<ToCopyBackward0>), 'll_feats': tensor([[ 2.7301e+01,  6.3240e+00,  1.4166e+01,  6.2673e+01, -1.3059e+00,\n",
      "          3.6327e+01,  9.2264e+00, -1.5421e-01,  3.5196e+01,  4.9831e+01,\n",
      "         -1.1380e+00,  2.7568e+01,  1.4750e+01,  2.1301e+01, -2.1581e+00],\n",
      "        [ 2.7294e+01,  4.1858e+00,  1.5249e+01,  6.8740e+01, -1.4974e+00,\n",
      "          4.0718e+01,  9.7011e+00, -5.9761e-01,  3.9841e+01,  5.4140e+01,\n",
      "         -1.0893e+00,  2.9069e+01,  1.4632e+01,  2.2499e+01, -2.0066e+00],\n",
      "        [ 2.8109e+01,  3.9090e+00,  1.7011e+01,  7.3007e+01, -1.1348e+00,\n",
      "          4.1494e+01,  9.3176e+00,  1.0256e+00,  4.3412e+01,  5.7245e+01,\n",
      "         -9.2421e-01,  2.8493e+01,  1.3806e+01,  2.1002e+01, -1.8779e+00],\n",
      "        [ 2.8324e+01,  6.0853e+00,  1.5509e+01,  6.7184e+01, -9.2381e-01,\n",
      "          3.8999e+01,  8.8772e+00,  8.2288e-01,  3.7791e+01,  5.3202e+01,\n",
      "         -1.0050e+00,  2.8615e+01,  1.4442e+01,  2.1690e+01, -2.1469e+00],\n",
      "        [ 2.6965e+01,  4.9379e+00,  1.5734e+01,  6.6358e+01, -1.0694e+00,\n",
      "          3.9181e+01,  9.3732e+00,  4.9294e-01,  3.7852e+01,  5.2883e+01,\n",
      "         -1.0992e+00,  2.8284e+01,  1.4541e+01,  2.2165e+01, -2.1058e+00],\n",
      "        [ 2.8935e+01,  5.9297e+00,  1.2866e+01,  6.5984e+01, -9.7951e-01,\n",
      "          3.9027e+01,  9.0794e+00, -6.4663e-02,  3.5823e+01,  5.0633e+01,\n",
      "         -1.2063e+00,  2.9226e+01,  1.7405e+01,  2.5424e+01, -2.1637e+00],\n",
      "        [ 2.8623e+01,  5.6241e+00,  1.6074e+01,  7.0039e+01, -1.1654e+00,\n",
      "          3.8966e+01,  9.1383e+00,  5.9783e-01,  3.9700e+01,  5.5134e+01,\n",
      "         -9.9302e-01,  2.7876e+01,  1.3233e+01,  2.0897e+01, -2.0654e+00],\n",
      "        [ 2.7789e+01,  4.9807e+00,  1.5594e+01,  6.7922e+01, -1.0319e+00,\n",
      "          3.8615e+01,  8.8931e+00,  1.1553e+00,  3.7123e+01,  5.2420e+01,\n",
      "         -1.0701e+00,  2.7995e+01,  1.4508e+01,  2.2501e+01, -2.0417e+00],\n",
      "        [ 2.8896e+01,  5.0201e+00,  1.4715e+01,  7.2519e+01, -4.0892e-01,\n",
      "          4.0633e+01,  8.4643e+00,  1.0695e+00,  4.2040e+01,  5.6775e+01,\n",
      "         -9.4541e-01,  2.7700e+01,  1.4637e+01,  2.2525e+01, -1.9366e+00],\n",
      "        [ 2.7107e+01,  6.2015e+00,  1.4279e+01,  6.3565e+01, -1.6475e+00,\n",
      "          3.7188e+01,  8.7826e+00, -5.6282e-01,  3.5004e+01,  5.1070e+01,\n",
      "         -1.2180e+00,  2.8249e+01,  1.3663e+01,  2.0940e+01, -2.2042e+00]],\n",
      "       dtype=torch.float64, grad_fn=<ToCopyBackward0>), 'll_feats_grad_F': tensor([[[-3.0030e+00, -8.4952e+00,  1.3527e+01,  ...,  5.5847e+00,\n",
      "           1.6405e+00,  3.7725e-01],\n",
      "         [-4.7092e+00,  2.3409e+00,  8.1269e+00,  ..., -2.0064e+01,\n",
      "          -2.3035e+01, -4.5426e-01],\n",
      "         [-1.8139e+00, -3.7595e+00,  1.1160e+00,  ..., -1.2512e+01,\n",
      "          -1.7660e+01,  2.5302e-01]],\n",
      "\n",
      "        [[-5.6282e+00,  6.8154e-01,  8.3504e+00,  ..., -1.5080e+01,\n",
      "          -1.6268e+01, -7.9004e-01],\n",
      "         [ 5.5212e+00, -2.4108e-02, -1.5167e+01,  ...,  2.1715e+01,\n",
      "           2.6049e+01,  2.8899e-01],\n",
      "         [-9.3256e-01, -4.1408e-01,  3.5586e+00,  ..., -4.0377e+00,\n",
      "          -4.8600e+00,  1.6921e-01]],\n",
      "\n",
      "        [[ 2.2290e+00,  5.7653e-01, -2.8002e-01,  ..., -1.1154e+01,\n",
      "          -1.3518e+01, -1.3425e-01],\n",
      "         [ 2.5583e+00,  1.7101e+00, -3.6804e+00,  ...,  5.8178e+00,\n",
      "           5.3157e+00, -3.0812e-01],\n",
      "         [ 6.5662e-01,  4.1343e-01,  1.4621e+00,  ...,  6.0932e+00,\n",
      "           8.0405e+00, -2.2940e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1337e+00, -3.0239e+00,  2.6989e+00,  ..., -1.8837e-01,\n",
      "          -2.5203e+00,  2.8075e-01],\n",
      "         [ 5.9288e+00,  1.0264e+00, -1.1280e+01,  ...,  1.5236e+01,\n",
      "           2.2117e+01, -1.4424e-01],\n",
      "         [-5.1631e+00, -4.1769e+00,  1.0286e+01,  ..., -5.1135e+00,\n",
      "          -1.1662e+01,  3.0380e-01]],\n",
      "\n",
      "        [[-1.3685e+00, -2.1198e+00,  3.0459e+00,  ..., -1.5020e-01,\n",
      "          -9.5302e-01,  1.6618e-01],\n",
      "         [-1.4906e+00, -3.3793e+00,  7.5222e+00,  ..., -7.2501e+00,\n",
      "          -8.5346e+00,  1.6743e-01],\n",
      "         [ 4.2104e-02, -2.4836e+00,  6.5151e+00,  ..., -1.0339e+01,\n",
      "          -1.2486e+01,  5.1119e-02]],\n",
      "\n",
      "        [[ 1.6344e+00,  4.0222e-01, -2.4142e+00,  ...,  2.6482e+00,\n",
      "           3.8919e+00, -2.7706e-02],\n",
      "         [-1.5187e+00,  2.4212e+00, -6.6999e-01,  ...,  3.4381e-01,\n",
      "          -7.6351e-01, -2.2104e-01],\n",
      "         [ 1.2807e+00, -3.8294e-01, -2.4487e+00,  ...,  1.7517e+00,\n",
      "           3.5076e+00,  5.5403e-02]]], dtype=torch.float64,\n",
      "       grad_fn=<ToCopyBackward0>), 'uncertainty': tensor([[1.0191e-08],\n",
      "        [1.0568e-08],\n",
      "        [1.0485e-08],\n",
      "        [1.0474e-08],\n",
      "        [1.0606e-08],\n",
      "        [1.1329e-08],\n",
      "        [1.0562e-08],\n",
      "        [1.0370e-08],\n",
      "        [1.0299e-08],\n",
      "        [1.1275e-08]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "for batch in ethanol_data.test_dataloader():\n",
    "    result = llpr_model(batch)\n",
    "    print(\"Result dictionary:\", result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import schnetpack as spk\n",
    "import schnetpack.transform as trn\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%rm -r testtut\n",
    "testtut = './testtut'\n",
    "if not os.path.exists(testtut):\n",
    "    os.makedirs(testtut)\n",
    "    \n",
    "\n",
    "\n",
    "n_atoms = 4\n",
    "positions = np.array([\n",
    "    [5.88321935, 2.88297608, 6.11028356],\n",
    "    [3.55048572, 4.80964742, 2.77677731],\n",
    "    [0.40720652, 6.73142071, 3.88666154],\n",
    "    [2.73860477, 0.96144918, 0.55409947],\n",
    "])\n",
    "cell = np.array([\n",
    "    [6.287023489207423, -0.00034751886075738795, -0.0008093810364881463],\n",
    "    [0.00048186949720712026, 7.696440684406158, -0.001909478919115524],\n",
    "    [0.0010077843421425583, -0.0033467698530393886, 6.666654324468158],\n",
    "])\n",
    "symbols=[\"Si\"]*n_atoms\n",
    "energy = np.array([-10169.33552017])\n",
    "forces = np.array([\n",
    "    [ 0.02808107, -0.02261815, -0.00868415],\n",
    "    [-0.03619687, -0.02530285, -0.00912962],\n",
    "    [-0.03512621,  0.02608594,  0.00913623],\n",
    "    [ 0.02955523,  0.02289934,  0.0089936 ],\n",
    "])\n",
    "stress = np.array([[\n",
    "    [-2.08967984e-02,  1.52890659e-06,  1.44133597e-06],\n",
    "    [ 1.52890659e-06, -6.45087059e-03, -7.26463797e-04],\n",
    "    [ 1.44133597e-06, -7.26463797e-04, -6.04950702e-03],\n",
    "]])\n",
    "\n",
    "from ase import Atoms\n",
    "\n",
    "atoms = []\n",
    "data = []\n",
    "\n",
    "for i in range(5):\n",
    "    atoms.append(Atoms(\n",
    "        symbols=symbols,\n",
    "        positions=positions + np.random.rand(4, 3),\n",
    "        cell=cell,\n",
    "        pbc=True,\n",
    "    ))\n",
    "    \n",
    "    data.append(dict(\n",
    "        energy=np.array(energy),\n",
    "        forces=np.array(forces) + np.random.rand(4, 3),\n",
    "        stress=np.array(stress) + np.random.rand(3, 3),\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schnetpack.data import create_dataset, AtomsDataFormat\n",
    "\n",
    "%rm si.db\n",
    "db_path = \"./si.db\"\n",
    "new_dataset = create_dataset(\n",
    "    datapath=db_path,\n",
    "    format=AtomsDataFormat.ASE,\n",
    "    distance_unit='Ang',\n",
    "    property_unit_dict=dict(\n",
    "        energy=\"eV\",\n",
    "        forces=\"eV/Ang\",\n",
    "        stress=\"eV/Ang/Ang/Ang\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "new_dataset.add_systems(\n",
    "    property_list=data,\n",
    "    atoms_list=atoms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm split.npz\n",
    "\n",
    "custom_data = spk.data.AtomsDataModule(\n",
    "    './si.db', \n",
    "    batch_size=2,\n",
    "    distance_unit='Ang',\n",
    "    property_units={'energy':'eV', 'forces':'eV/Ang', 'stress':'eV/Ang/Ang/Ang'},\n",
    "    num_train=3,\n",
    "    num_val=2,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=5.),\n",
    "        #trn.RemoveOffsets(\"energy\", remove_mean=True, remove_atomrefs=False),\n",
    "        trn.CastTo32(),\n",
    "    ],\n",
    "    num_workers=1,\n",
    "    pin_memory=True, # set to false, when not using a GPU\n",
    ")\n",
    "custom_data.prepare_data()\n",
    "custom_data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5.\n",
    "n_atom_basis = 30\n",
    "\n",
    "pairwise_distance = spk.atomistic.PairwiseDistances() # calculates pairwise distances between atoms\n",
    "strain = spk.atomistic.Strain()\n",
    "radial_basis = spk.nn.GaussianRBF(n_rbf=20, cutoff=cutoff)\n",
    "schnet = spk.representation.SchNet(\n",
    "    n_atom_basis=n_atom_basis, n_interactions=3,\n",
    "    radial_basis=radial_basis,\n",
    "    cutoff_fn=spk.nn.CosineCutoff(cutoff)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_energy = spk.atomistic.Atomwise(n_in=n_atom_basis, output_key=\"energy\")\n",
    "pred_forces = spk.atomistic.Forces(energy_key=\"energy\", force_key=\"forces\")#, stress_key=\"stress\", calc_stress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=schnet,\n",
    "    input_modules=[pairwise_distance],#, strain],\n",
    "    output_modules=[pred_energy, pred_forces],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_energy = spk.task.ModelOutput(\n",
    "    name=\"energy\",\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=0.20,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")\n",
    "\n",
    "output_forces = spk.task.ModelOutput(\n",
    "    name=\"forces\",\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=0.40,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")\n",
    "\n",
    "output_stress = spk.task.ModelOutput(\n",
    "    name=\"stress\",\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=0.40,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    outputs=[output_energy, output_forces],#, output_stress],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Missing logger folder: ./testtut/lightning_logs\n",
      "\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | model   | NeuralNetworkPotential | 16.4 K\n",
      "1 | outputs | ModuleList             | 0     \n",
      "---------------------------------------------------\n",
      "16.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.4 K    Total params\n",
      "0.066     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/sanggyu/miniconda3/envs/schnet/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2/2 [00:10<00:00,  0.20it/s, v_num=0, val_loss=2.07e+7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2/2 [00:10<00:00,  0.20it/s, v_num=0, val_loss=2.07e+7]\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir=testtut)\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(testtut, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=testtut,\n",
    "    max_epochs=3, # for testing, we restrict the number of epochs\n",
    "    accelerator=\"cpu\",\n",
    ")\n",
    "trainer.fit(task, datamodule=custom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10169.3359, -10169.3359])\n",
      "Result dictionary: {'energy': tensor([3.6537, 3.6408], grad_fn=<SqueezeBackward1>), 'forces': tensor([[ 0.0163, -0.0796, -0.0016],\n",
      "        [ 0.3519, -0.0390, -0.1039],\n",
      "        [-0.3601,  0.0364,  0.0942],\n",
      "        [-0.0082,  0.0822,  0.0113],\n",
      "        [-0.2754,  0.0590, -0.1150],\n",
      "        [-0.2872, -0.1061, -0.0509],\n",
      "        [ 0.2895,  0.1560,  0.0880],\n",
      "        [ 0.2731, -0.1089,  0.0779]], grad_fn=<NegBackward0>), 'll_feats': tensor([[-1.0263,  1.1874, -0.6239,  0.9357,  2.2836,  2.2531,  0.6957, -1.0439,\n",
      "         -0.0508,  2.2132,  1.6197,  3.4521, -0.7162, -0.5474,  2.2243],\n",
      "        [-1.0181,  1.1538, -0.6222,  0.9569,  2.3098,  2.1496,  0.6442, -1.0430,\n",
      "         -0.0246,  2.0875,  1.6368,  3.4019, -0.6883, -0.5433,  2.0529]],\n",
      "       grad_fn=<SqueezeBackward1>), 'll_feats_per_atom': tensor([[-0.2566,  0.2990, -0.1553,  0.2315,  0.5668,  0.5754,  0.1814, -0.2608,\n",
      "         -0.0161,  0.5735,  0.4020,  0.8656, -0.1823, -0.1377,  0.5813],\n",
      "        [-0.2564,  0.2944, -0.1568,  0.2365,  0.5752,  0.5498,  0.1654, -0.2610,\n",
      "         -0.0087,  0.5325,  0.4087,  0.8603, -0.1755, -0.1363,  0.5295],\n",
      "        [-0.2565,  0.2948, -0.1567,  0.2361,  0.5751,  0.5512,  0.1667, -0.2611,\n",
      "         -0.0091,  0.5331,  0.4081,  0.8608, -0.1759, -0.1361,  0.5311],\n",
      "        [-0.2568,  0.2991, -0.1550,  0.2315,  0.5665,  0.5766,  0.1822, -0.2609,\n",
      "         -0.0168,  0.5740,  0.4008,  0.8655, -0.1825, -0.1374,  0.5824],\n",
      "        [-0.2542,  0.2890, -0.1567,  0.2321,  0.5818,  0.5375,  0.1730, -0.2614,\n",
      "         -0.0023,  0.5089,  0.4103,  0.8470, -0.1720, -0.1352,  0.5044],\n",
      "        [-0.2544,  0.2873, -0.1550,  0.2470,  0.5736,  0.5335,  0.1463, -0.2599,\n",
      "         -0.0082,  0.5333,  0.4109,  0.8534, -0.1716, -0.1371,  0.5183],\n",
      "        [-0.2558,  0.2938, -0.1558,  0.2406,  0.5733,  0.5485,  0.1629, -0.2606,\n",
      "         -0.0109,  0.5386,  0.4070,  0.8593, -0.1753, -0.1361,  0.5335],\n",
      "        [-0.2537,  0.2837, -0.1548,  0.2372,  0.5811,  0.5301,  0.1620, -0.2611,\n",
      "         -0.0031,  0.5068,  0.4086,  0.8422, -0.1695, -0.1349,  0.4967]],\n",
      "       grad_fn=<SiluBackward0>), 'll_feats_grad_F': tensor([[[-2.1032e-03,  1.2370e-02, -1.2244e-03,  5.1170e-03, -6.7114e-03,\n",
      "           2.5089e-02,  5.9212e-03,  8.9222e-04, -1.0114e-02,  3.1618e-02,\n",
      "          -7.5159e-03,  2.2939e-02, -6.2768e-03,  1.9095e-03,  4.1040e-02],\n",
      "         [ 6.7572e-03, -1.8665e-02, -4.4958e-03, -6.1854e-02,  3.8759e-02,\n",
      "          -2.1121e-02,  7.5601e-02, -4.4439e-03,  3.7951e-02, -1.0720e-01,\n",
      "           1.5391e-02, -5.3492e-02,  6.9392e-03, -1.6858e-03, -8.8547e-02],\n",
      "         [ 6.2460e-04,  1.6557e-02, -1.1692e-02, -1.4108e-02,  5.7224e-03,\n",
      "          -7.5611e-04,  1.7383e-02,  7.8794e-05,  1.5567e-02, -1.8879e-04,\n",
      "           2.9049e-02,  1.5513e-02, -4.8095e-03, -7.4456e-03,  3.3772e-03]],\n",
      "\n",
      "        [[-3.8438e-02,  8.0099e-02, -3.3199e-02,  1.4585e-01, -9.5590e-02,\n",
      "           3.4117e-02, -3.5719e-01,  1.1101e-02, -4.2905e-02,  1.8790e-01,\n",
      "           5.2155e-02,  2.9231e-01, -1.6648e-02, -7.0452e-03,  1.3030e-01],\n",
      "         [ 1.8889e-02, -5.9214e-02,  3.3342e-02,  6.8714e-02, -1.4091e-02,\n",
      "          -7.8755e-02, -4.6530e-02,  6.3100e-03, -2.8154e-02,  4.5624e-02,\n",
      "          -3.7522e-02, -1.0974e-01,  2.2732e-02,  8.7863e-04, -2.0114e-02],\n",
      "         [ 3.1702e-03, -7.2002e-03,  2.0015e-02, -4.1279e-02,  1.2048e-02,\n",
      "           5.1596e-02,  1.4703e-01, -6.5141e-03, -2.2918e-02,  2.9643e-03,\n",
      "          -5.3022e-02, -8.0184e-02, -7.7692e-03,  5.7078e-03,  4.8348e-02]],\n",
      "\n",
      "        [[ 4.3744e-02, -9.2638e-02,  2.7406e-02, -1.4667e-01,  1.0525e-01,\n",
      "          -8.7667e-02,  3.2776e-01, -1.0090e-02,  6.8080e-02, -2.2488e-01,\n",
      "          -1.6870e-02, -3.1121e-01,  2.6175e-02, -1.7321e-03, -1.9380e-01],\n",
      "         [-1.8954e-02,  5.0183e-02, -2.9712e-02, -6.1548e-02,  1.1786e-02,\n",
      "           6.6952e-02,  3.1369e-02, -6.6160e-03,  2.6272e-02, -5.2136e-02,\n",
      "           3.2594e-02,  9.6757e-02, -1.8592e-02, -4.7545e-04,  4.3818e-03],\n",
      "         [-5.1904e-03, -1.5280e-02, -5.6028e-03,  5.1531e-02, -1.7024e-02,\n",
      "          -5.9954e-02, -1.6541e-01,  4.4316e-03,  8.6019e-03, -1.6977e-02,\n",
      "           2.5308e-02,  4.8111e-02,  1.4836e-02, -2.2237e-04, -6.8826e-02]],\n",
      "\n",
      "        [[-3.2026e-03,  1.6882e-04,  7.0172e-03, -4.2949e-03, -2.9443e-03,\n",
      "           2.8460e-02,  2.3511e-02, -1.9030e-03, -1.5060e-02,  5.3519e-03,\n",
      "          -2.7769e-02, -4.0442e-03, -3.2503e-03,  6.8678e-03,  2.2452e-02],\n",
      "         [-6.6922e-03,  2.7695e-02,  8.6593e-04,  5.4689e-02, -3.6455e-02,\n",
      "           3.2924e-02, -6.0440e-02,  4.7499e-03, -3.6070e-02,  1.1371e-01,\n",
      "          -1.0464e-02,  6.6473e-02, -1.1080e-02,  1.2826e-03,  1.0428e-01],\n",
      "         [ 1.3956e-03,  5.9234e-03, -2.7194e-03,  3.8565e-03, -7.4690e-04,\n",
      "           9.1141e-03,  9.9656e-04,  2.0037e-03, -1.2513e-03,  1.4201e-02,\n",
      "          -1.3354e-03,  1.6560e-02, -2.2573e-03,  1.9601e-03,  1.7101e-02]],\n",
      "\n",
      "        [[ 5.1648e-02, -1.2066e-01,  5.0163e-02, -1.2603e-02,  8.3304e-02,\n",
      "          -1.9365e-01,  1.7520e-01, -2.5010e-03,  2.9271e-02, -2.3138e-01,\n",
      "          -4.7204e-02, -3.3261e-01,  5.8505e-02,  1.4782e-02, -2.7750e-01],\n",
      "         [-1.4972e-02,  5.0087e-02, -2.9180e-02, -1.3811e-02,  3.8108e-03,\n",
      "           2.0875e-02, -1.2358e-02, -2.2950e-03,  2.2314e-02, -4.3875e-02,\n",
      "           4.1753e-02,  9.4486e-02, -9.3968e-03, -3.7841e-04, -2.3798e-02],\n",
      "         [ 5.1204e-03,  3.1971e-03,  6.4526e-03, -7.5930e-02,  2.1080e-02,\n",
      "           5.7725e-02,  1.6612e-01, -6.5290e-03,  2.1639e-03,  1.6113e-03,\n",
      "          -1.9220e-02, -6.4519e-02, -1.4964e-02, -3.5329e-03,  5.5722e-02]],\n",
      "\n",
      "        [[ 2.5520e-02, -3.0933e-02,  1.7545e-02, -1.5416e-01,  6.7983e-02,\n",
      "           3.2856e-02,  3.4734e-01, -1.2123e-02,  3.4685e-02, -1.1221e-01,\n",
      "          -3.3951e-02, -1.9672e-01, -6.7767e-03,  3.6351e-03, -1.7018e-02],\n",
      "         [ 1.6539e-02, -3.5921e-02,  2.7122e-02, -1.1046e-02,  7.3458e-03,\n",
      "          -6.0582e-03,  9.9455e-02, -7.6108e-04, -1.6719e-02,  7.0720e-03,\n",
      "          -4.9760e-02, -1.0868e-01,  5.5682e-03,  7.6471e-03,  1.8844e-02],\n",
      "         [ 5.3044e-03, -1.4715e-02,  1.7701e-02, -9.6103e-03,  1.6554e-03,\n",
      "           2.2368e-02,  6.4690e-02, -1.3514e-03, -2.0420e-02,  1.3884e-02,\n",
      "          -4.3234e-02, -4.6733e-02, -1.5452e-03,  8.4855e-03,  3.4413e-02]],\n",
      "\n",
      "        [[-2.0953e-02,  3.4479e-02, -2.8484e-02,  1.5098e-01, -6.0826e-02,\n",
      "          -5.8021e-02, -3.5686e-01,  1.4277e-02, -1.3368e-02,  1.0284e-01,\n",
      "           6.7674e-02,  2.0331e-01,  8.4529e-03, -1.1042e-02, -4.9767e-03],\n",
      "         [-1.1083e-02,  8.6071e-03, -1.9530e-02,  7.1262e-02, -2.2725e-02,\n",
      "          -5.2935e-02, -2.1280e-01,  7.1397e-03,  9.4080e-03,  1.2808e-02,\n",
      "           5.0571e-02,  1.0572e-01,  1.0435e-02, -7.2305e-03, -5.1881e-02],\n",
      "         [-8.9793e-03,  2.3418e-02, -1.0607e-02,  3.5209e-02, -1.8781e-02,\n",
      "           1.4671e-02, -8.0492e-02,  3.6830e-03, -1.0204e-02,  4.2661e-02,\n",
      "           8.7104e-03,  7.8861e-02, -4.6875e-03,  4.1436e-04,  2.9259e-02]],\n",
      "\n",
      "        [[-5.6215e-02,  1.1712e-01, -3.9225e-02,  1.5785e-02, -9.0461e-02,\n",
      "           2.1882e-01, -1.6568e-01,  3.4746e-04, -5.0588e-02,  2.4075e-01,\n",
      "           1.3481e-02,  3.2602e-01, -6.0181e-02, -7.3749e-03,  2.9950e-01],\n",
      "         [ 9.5157e-03, -2.2773e-02,  2.1589e-02, -4.6405e-02,  1.1568e-02,\n",
      "           3.8118e-02,  1.2570e-01, -4.0837e-03, -1.5003e-02,  2.3995e-02,\n",
      "          -4.2564e-02, -9.1531e-02, -6.6067e-03, -3.8234e-05,  5.6835e-02],\n",
      "         [-1.4456e-03, -1.1901e-02, -1.3547e-02,  5.0332e-02, -3.9543e-03,\n",
      "          -9.4764e-02, -1.5031e-01,  4.1973e-03,  2.8460e-02, -5.8157e-02,\n",
      "           5.3743e-02,  3.2390e-02,  2.1197e-02, -5.3669e-03, -1.1939e-01]]],\n",
      "       grad_fn=<NegBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ase import Atoms\n",
    "\n",
    "best_model = torch.load(os.path.join(testtut, 'best_inference_model'), map_location='cpu')\n",
    "\n",
    "llpr_model = spk.model.LLPredRigidityNNP(best_model, consider_ll_feat_gradients=True, save_ll_feat_per_atom=True)\n",
    "\n",
    "for batch in custom_data.train_dataloader():\n",
    "    print(batch['energy'])\n",
    "    result = llpr_model(batch)\n",
    "    print(\"Result dictionary:\", result)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6777, 3.6537], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schnetpack.utils.llpr import calibrate_llpr_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters found beyond the designated parameter space!\n",
      "Calibrated LLPR parameters:\tC = 1.7063E+05\tsigma = 1.6512E-04\n"
     ]
    }
   ],
   "source": [
    "weight_dict = {'E': 1, 'F': 1, 'S': 1}\n",
    "\n",
    "llpr_model.compute_covariance(custom_data.train_dataloader(), weights=weight_dict)\n",
    "\n",
    "calibrate_llpr_params(llpr_model, custom_data.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
